{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwlPAA8ZJUsr"
      },
      "source": [
        "Copyright (C) 2019-2023 Software Platform Lab, Seoul National University\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); \n",
        "\n",
        "you may not use this file except in compliance with the License. \n",
        "\n",
        "You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 \n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software \n",
        "\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS, \n",
        "\n",
        "\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
        "\n",
        "\n",
        "See the License for the specific language governing permissions and\n",
        "\n",
        "\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO8dQBJs5Yxh"
      },
      "source": [
        "## Defining a model in TensorFlow \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV9KmwLR_wBQ"
      },
      "source": [
        "In TensorFlow, various libraries regarding the model definition are provided under `tf.keras`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqWzzFUO79nx"
      },
      "source": [
        "### Model Subclassing\n",
        "We can build a fully-customizable model by **subclassing [tf.keras.Model]** (https://www.tensorflow.org/api_docs/python/tf/keras/models/Model) and **defining your own forward pass.** **Layers** are created in the `__init__` method, provided by the [tf.keras.layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers)  and they are set as attributes of the class instance. **The forward pass is defined in the `call` method.** You can access **model variables by `model.trainable_variables`.**\n",
        "\n",
        "Below is an example of **a linear regression model** to be defined as a subclass of `tf.keras.Model`, and then be trained using loss function, gradient function and optimizer provided in [tf.keras.optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers). Useful loss functions are also provided in [tf.keras.losses](https://www.tensorflow.org/api_docs/python/tf/keras/losses). We will cover these in more detail as we go on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu-X05yCDq9V"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRHEy317_-s0"
      },
      "source": [
        "NUM_EXAMPLES = 2000\n",
        "# 2000*1 형태의 정규 분포 난수 만들기\n",
        "toy_inputs = tf.random.normal([NUM_EXAMPLES, 1])\n",
        "noise = tf.random.normal([NUM_EXAMPLES, 1])\n",
        "toy_outputs = toy_inputs * 2 - 1 + noise * 1/4"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toy_inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cZS-96GiGbD",
        "outputId": "28cb2961-69e6-43f7-a9f9-6731fe2ac507"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2000, 1), dtype=float32, numpy=\n",
              "array([[ 0.08734757],\n",
              "       [-0.61965317],\n",
              "       [ 0.9665108 ],\n",
              "       ...,\n",
              "       [-0.0677831 ],\n",
              "       [ 1.4166945 ],\n",
              "       [ 0.21652994]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy1x6VF-_-s1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4923eda6-6cf8-4905-ea72-ac21e298ae9d"
      },
      "source": [
        "class ToyModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        \"\"\"Define layers\"\"\"\n",
        "        super(ToyModel, self).__init__()\n",
        "        self.dense = tf.keras.layers.Dense(units=1)\n",
        "\n",
        "    def call(self, input):\n",
        "        \"\"\"Define forward pass.\"\"\"\n",
        "        result = self.dense(input)        \n",
        "        return result\n",
        "\n",
        "\n",
        "# The loss function to be optimized (MSE loss)\n",
        "def loss(model, inputs, targets):\n",
        "    error = model(inputs) - targets\n",
        "    return tf.reduce_mean(tf.square(error)) # 평균제곱오차\n",
        "\n",
        "optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.01)\n",
        "\n",
        "model = ToyModel()\n",
        "print(\"Initial loss: {:.3f}\".format(loss(model, toy_inputs, toy_outputs)))\n",
        "print(\"Trainable variables:\")\n",
        "for var in model.trainable_variables:\n",
        "  print(\"\\t\", var.name, \": \", var.numpy())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial loss: 3.503\n",
            "Trainable variables:\n",
            "\t toy_model/dense_5/kernel:0 :  [[0.47264993]]\n",
            "\t toy_model/dense_5/bias:0 :  [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ3w_EmG7shn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f327121-6028-4896-d5c1-717a5d04f7bf"
      },
      "source": [
        "# Training loop\n",
        "## GradientTape: 자동 미분을 통해 동적으로 Gradient 값들을 확인해 볼 수 있다는 장점\n",
        "for i in range(300):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, toy_inputs, toy_outputs)\n",
        "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "    # backpropagation: weight 업데이트\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    if i % 20 == 0:\n",
        "        print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model, toy_inputs, toy_outputs)))\n",
        "\n",
        "print(\"Final loss: {:.3f}\".format(loss(model, toy_inputs, toy_outputs)))\n",
        "print(\"Trainable variables:\")\n",
        "for var in model.trainable_variables:\n",
        "  print(\"\\t\", var.name, \": \", var.numpy())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at step 000: 3.364\n",
            "Loss at step 020: 1.507\n",
            "Loss at step 040: 0.695\n",
            "Loss at step 060: 0.340\n",
            "Loss at step 080: 0.185\n",
            "Loss at step 100: 0.117\n",
            "Loss at step 120: 0.088\n",
            "Loss at step 140: 0.075\n",
            "Loss at step 160: 0.069\n",
            "Loss at step 180: 0.066\n",
            "Loss at step 200: 0.065\n",
            "Loss at step 220: 0.065\n",
            "Loss at step 240: 0.065\n",
            "Loss at step 260: 0.065\n",
            "Loss at step 280: 0.065\n",
            "Final loss: 0.065\n",
            "Trainable variables:\n",
            "\t toy_model/dense_5/kernel:0 :  [[2.0078015]]\n",
            "\t toy_model/dense_5/bias:0 :  [-0.9951335]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8MEnHhAvskB"
      },
      "source": [
        "It's not required to set an input shape for the `tf.keras.Model` class since the parameters are set the first time input is passed to the layer.\n",
        "\n",
        "tf.keras.layers classes create and contain their own model variables that are tied to the lifetime of their layer objects. To share layer variables, share their objects.\n",
        "\n",
        "Below examples shows a new model that relies on the previous toy model. We are going to employ an additional bias to fit a slightly different data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFF5jQ___-s7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6d10fb-f4a8-4c52-d6cc-0b1aa1e76429"
      },
      "source": [
        "toy_outputs_2 = toy_outputs + 3\n",
        "\n",
        "class ToyModel2(tf.keras.Model):\n",
        "    def __init__(self, toy_model):\n",
        "        \"\"\"Define layers\"\"\"\n",
        "        super(ToyModel2, self).__init__()\n",
        "        self.toy_model = toy_model\n",
        "        self.b = tf.Variable(0., name='another_bias')\n",
        "\n",
        "    def call(self, input):\n",
        "        \"\"\"Define forward pass.\"\"\"\n",
        "        result = self.toy_model(input)        \n",
        "        return result + self.b\n",
        "\n",
        "\n",
        "model2 = ToyModel2(model)\n",
        "print(\"Initial loss: {:.3f}\".format(loss(model2, toy_inputs, toy_outputs_2)))\n",
        "print(\"Trainable variables:\")\n",
        "for var in model2.trainable_variables:\n",
        "  print(\"\\t\", var.name, \": \", var.numpy())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial loss: 9.053\n",
            "Trainable variables:\n",
            "\t toy_model/dense_5/kernel:0 :  [[2.0078015]]\n",
            "\t toy_model/dense_5/bias:0 :  [-0.9951335]\n",
            "\t another_bias:0 :  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZf0cTk7_-s9"
      },
      "source": [
        "We are only optimizing the additional bias. The weight and bias of toy_model_1 does not change."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhNlE5mTw7bX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97438aaf-dfa9-4bb3-b4bd-c2286e9add3d"
      },
      "source": [
        "# Training loop\n",
        "for i in range(300):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model2, toy_inputs, toy_outputs_2)\n",
        "    grads = tape.gradient(loss_value, [model2.b]) # gradient w.r.t. `model2.b`, not `model2.trainable_variables`\n",
        "    optimizer.apply_gradients(zip(grads, [model2.b])) # optimize only `model2.b`\n",
        "    if i % 20 == 0:\n",
        "        print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model2, toy_inputs, toy_outputs_2)))\n",
        "\n",
        "print(\"Final loss: {:.3f}\".format(loss(model2, toy_inputs, toy_outputs_2)))\n",
        "print(\"Trainable variables:\")\n",
        "for var in model2.trainable_variables:\n",
        "  print(\"\\t\", var.name, \": \", var.numpy())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at step 000: 8.697\n",
            "Loss at step 020: 3.912\n",
            "Loss at step 040: 1.779\n",
            "Loss at step 060: 0.829\n",
            "Loss at step 080: 0.405\n",
            "Loss at step 100: 0.216\n",
            "Loss at step 120: 0.132\n",
            "Loss at step 140: 0.095\n",
            "Loss at step 160: 0.078\n",
            "Loss at step 180: 0.071\n",
            "Loss at step 200: 0.067\n",
            "Loss at step 220: 0.066\n",
            "Loss at step 240: 0.065\n",
            "Loss at step 260: 0.065\n",
            "Loss at step 280: 0.065\n",
            "Final loss: 0.065\n",
            "Trainable variables:\n",
            "\t toy_model/dense_5/kernel:0 :  [[2.0078015]]\n",
            "\t toy_model/dense_5/bias:0 :  [-0.9951335]\n",
            "\t another_bias:0 :  2.9911287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjAodT-v_-r7"
      },
      "source": [
        "## Convolutional Neural Networks\n",
        "Build simple CNN in TensorFlow.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LQHVwI1g_PF"
      },
      "source": [
        "### Preparing MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LydTwAzMhHw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd396b26-141b-438c-ec27-5516bcf2b7c8"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Download the mnist dataset using keras\n",
        "data_train, data_test = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Parse images and labels\n",
        "(train_images, train_labels) = data_train\n",
        "(test_images, test_labels) = data_test\n",
        "\n",
        "# Numpy reshape & type casting\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_labels = train_labels.astype('int64')\n",
        "test_labels = test_labels.astype('int64')\n",
        "\n",
        "\n",
        "# Normalizing the images to the range of [0., 1.]\n",
        "train_images /= 255.\n",
        "test_images /= 255.\n",
        "\n",
        "print(train_images.shape, train_labels.shape)\n",
        "print(test_images.shape, test_labels.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1) (60000,)\n",
            "(10000, 28, 28, 1) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ5XuFPCBOZR"
      },
      "source": [
        "### Define the CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_USTku5_-r8"
      },
      "source": [
        "from tensorflow.keras import Model\n",
        "# Construct a tf.keras.model using tf.keras\n",
        "class MyCNN(Model):\n",
        "  def __init__(self):\n",
        "    super(MyCNN, self).__init__()\n",
        "    self.conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='valid')\n",
        "    self.conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='valid')\n",
        "    self.conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='valid')\n",
        "    self.maxpool = tf.keras.layers.MaxPooling2D((2, 2))\n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "    self.dense1 = tf.keras.layers.Dense(256, activation='relu')\n",
        "    self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense1(x)\n",
        "    x = self.dense2(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "# Create model\n",
        "model = MyCNN()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk4Cg8gRpWH_"
      },
      "source": [
        "### Setting up training\n",
        "After the model is constructed, we specify optimizer and loss function. We can also monitor training using metrics:\n",
        "* `optimizer`: This field specifies which optimizer to use. We can pass an optimizer instance (e.g., `tf.keras.optimizers.Adam`, `tf.keras.optimizers.RMSProp`), which are defined in  `tf.train` module.\n",
        "* `loss`: The function to minimize during optimization. Common choices include `mean square error (mse)`, `[categorical|binary]_crossentropy`. Loss functions are specified by name or by passing a callable object from the `tf.keras.losses` module.\n",
        "* `metrics`: Used to monitor training. We can put string names or callables defined in `tf.keras.metrics` module (e.g. `'accuracy'`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cBrLLCDpq2a"
      },
      "source": [
        "# Choose loss function and optimizer for training\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# Metrics to measure loss and accuracy of the model\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXKIy_UECa7P"
      },
      "source": [
        "### Train and Test functions using `tf.function`\n",
        "By annotating a train function with `tf.function`, TensorFlow internally **creates a graph so that it can benefit from graph-based execution.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUZYje1bC1xB"
      },
      "source": [
        "# Define function for training\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images, training=True)\n",
        "    loss = loss_fn(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)\n",
        "\n",
        "# Define function for testing\n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  predictions = model(images, training=False)\n",
        "  loss = loss_fn(labels, predictions)\n",
        "\n",
        "  test_loss(loss)\n",
        "  test_accuracy(labels, predictions)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDilJK1dC4f_"
      },
      "source": [
        "### Prepare the dataset and start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "797JZG-zDBFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d6dbb0f-d565-4f1d-a6ba-4411610dac6f"
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "# Prepare the dataset using tf.data\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_ds = train_ds.shuffle(10000)\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_ds = test_ds.batch(batch_size)\n",
        "\n",
        "\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Reset the metrics at each epoch\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "\n",
        "    for images, labels in train_ds:\n",
        "      train_step(images, labels)\n",
        "\n",
        "    for images, labels in test_ds:\n",
        "      test_step(images, labels)\n",
        "\n",
        "    print('Epoch: %02d' % (epoch + 1),\n",
        "          'Loss = {:2.4f}'.format(train_loss.result()),\n",
        "          'Train accuracy = {:2.4f}'.format(train_accuracy.result()),\n",
        "          'Test loss = {:2.4f}'.format(test_loss.result()),\n",
        "          'Test accuracy = {:2.4f}'.format(test_accuracy.result()))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 Loss = 0.2982 Train accuracy = 0.9123 Test loss = 0.0908 Test accuracy = 0.9711\n",
            "Epoch: 02 Loss = 0.0808 Train accuracy = 0.9753 Test loss = 0.0831 Test accuracy = 0.9747\n",
            "Epoch: 03 Loss = 0.0575 Train accuracy = 0.9824 Test loss = 0.0505 Test accuracy = 0.9847\n",
            "Epoch: 04 Loss = 0.0467 Train accuracy = 0.9857 Test loss = 0.0533 Test accuracy = 0.9836\n",
            "Epoch: 05 Loss = 0.0375 Train accuracy = 0.9879 Test loss = 0.0625 Test accuracy = 0.9801\n",
            "Epoch: 06 Loss = 0.0321 Train accuracy = 0.9899 Test loss = 0.0411 Test accuracy = 0.9875\n",
            "Epoch: 07 Loss = 0.0260 Train accuracy = 0.9915 Test loss = 0.0536 Test accuracy = 0.9845\n",
            "Epoch: 08 Loss = 0.0232 Train accuracy = 0.9928 Test loss = 0.0385 Test accuracy = 0.9887\n",
            "Epoch: 09 Loss = 0.0183 Train accuracy = 0.9940 Test loss = 0.0530 Test accuracy = 0.9850\n",
            "Epoch: 10 Loss = 0.0188 Train accuracy = 0.9940 Test loss = 0.0437 Test accuracy = 0.9884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7f9KSx3D9kF"
      },
      "source": [
        "## More simplified process using Keras API\n",
        "Keras API provides much simpler version to define a model and train a model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvCIHyMGEPEo"
      },
      "source": [
        "### Defining a model\n",
        "Let's take a look how we can define a model using Keras API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8PUmEq5rO44"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "# Let's build a stack of *sequential* layers, which is\n",
        "# the most common form of neural network graphs.\n",
        "model = models.Sequential()\n",
        "\n",
        "# Adds a reshaping layer that transforms (28, 28, 1) to (784,)\n",
        "model.add(layers.Reshape((784,), input_shape=(28, 28, 1)))\n",
        "\n",
        "# Adds a dense layer with 128 units to the model\n",
        "model.add(layers.Dense(units=128, activation='relu'))\n",
        "\n",
        "# Adds another layer, which has L2 regularization applied to the kernel matrix\n",
        "model.add(layers.Dense(units=64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "\n",
        "# Adds a dense layer with 10 output units\n",
        "model.add(layers.Dense(units=10, activation='linear'))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJq7I5kOc1H-"
      },
      "source": [
        "### Setting up training\n",
        "After the model is constructed, `compile` method configures how to learn the model, by specifying optimizer, loss function and metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocskyx96c0UY"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSo7qrwZlOrl"
      },
      "source": [
        "### Training a model\n",
        "We can train the model using the `fit` method and then the model is \"fit\" to the training data. We can specify the training data to use (`images_train` and `labels_train`), how many epochs we will run (`epochs`), and how many items to be processed in a batch (`batch_size`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPOV-4VXk53s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f59d34-1cb7-48d8-c564-c662a669dd5f"
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=10, batch_size=128)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 3s 4ms/step - loss: 0.6769 - accuracy: 0.8972\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2775 - accuracy: 0.9468\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1980 - accuracy: 0.9600\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1624 - accuracy: 0.9663\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1410 - accuracy: 0.9707\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1262 - accuracy: 0.9739\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1132 - accuracy: 0.9768\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1046 - accuracy: 0.9792\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0971 - accuracy: 0.9803\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0897 - accuracy: 0.9824\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2ac85c0220>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymPOEP3BlivE"
      },
      "source": [
        "### Evaluating the model\n",
        "Finally, we evaluate the trained model using test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV5w-V99l0Di",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ede386f1-cd5a-4664-e01d-a441f0a8bdc2"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 0.1095 - accuracy: 0.9777 - 692ms/epoch - 2ms/step\n",
            "Test accuracy: 0.9776999950408936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4ORwtammNNb"
      },
      "source": [
        "### **Quiz**\n",
        "First, define a multi-layer model using Keras API following the CNN model defined in the beginning.\n",
        "\n",
        "The model should contain at least 3 convolutional layers, 2 max pooling layers, and 1 dense layer.\n",
        "\n",
        "The test accuracy after training should be higher than 99%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhKpYAgszdkI"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "############# Write here. #############\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='valid', input_shape=(28,28,1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='valid'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='valid'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(units=128, activation='softmax'))\n",
        "\n",
        "# Create model\n",
        "\n",
        "#######################################"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmnL8eeL613b"
      },
      "source": [
        "Using the model and `(train_images, train_labels)` above, let's train the model using the following configuration:\n",
        "* optimizer: `tf.keras.optimizers.Adam`\n",
        "* learning rate: 0.001\n",
        "* loss: `SparseCategoricalCrossentropy`\n",
        "* metrics: `accuracy`\n",
        "* batch size: 128\n",
        "* epochs: 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYjsv3g9nSoq",
        "outputId": "d23049c8-d857-4987-ffdf-e83c4ba5a192"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0tNzWLWz0bj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07bd5797-28d3-4891-8bfd-fea6c1515e8b"
      },
      "source": [
        "############# Write here. #############\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=128)\n",
        "#######################################\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 6s 5ms/step - loss: 0.3342 - accuracy: 0.9014\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0681 - accuracy: 0.9790\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0482 - accuracy: 0.9847\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0377 - accuracy: 0.9880\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0310 - accuracy: 0.9900\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0255 - accuracy: 0.9920\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0225 - accuracy: 0.9929\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0179 - accuracy: 0.9945\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0166 - accuracy: 0.9944\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0144 - accuracy: 0.9954\n",
            "313/313 - 1s - loss: 0.0274 - accuracy: 0.9909 - 1s/epoch - 4ms/step\n",
            "Test accuracy: 0.9908999800682068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOowIsLDs7J_"
      },
      "source": [
        "## Wrap-up\n",
        "\n",
        "So far, we have learned how we can define and train models in TensorFlow. For more information you can refer to [guides in TensorFlow official website](https://www.tensorflow.org/guide) and many other blog posts."
      ]
    }
  ]
}